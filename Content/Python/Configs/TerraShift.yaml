environment:
  type: TerraShift
  params:
    # Core environment params
    PlatformSize: 1.0
    MaxColumnHeight: 1.0
    ObjectSize: [0.10, 0.10, 0.10]
    ObjectMass: 0.2
    GridSize: 50
    MaxSteps: 1024
    NumGoals: 4
    SpawnDelay: 1.0
    RespawnDelay: 1.0
    MaxAgents: 10
    GoalThreshold: 0.2

    # Discrete 2D Fourier parameters
    PhaseXDeltaRange: [-0.1, 0.1]
    PhaseYDeltaRange: [-0.1, 0.1]
    FreqScaleDeltaRange: [-0.01, 0.01]
    MatrixDeltaRange: [-0.05, 0.05]
    K: 8  # number of fundamental modes

  shape:
    is_multi_agent: True
    # single_agent_obs_size:
    #   = 3 + (2*K x 2*K) from Fourier
    #   + 25 from environment data
    # If K=8 => single_agent_obs_size = (3 + 16*16) + 25 = 284
    single_agent_obs_size: 284
    max_agents: 10

    action_space:
      type: discrete
      # Each agent has 6 discrete actions
      # 0 -> dPhaseX (3 choices)
      # 1 -> dPhaseY (3 choices)
      # 2 -> dFreqScale (3 choices)
      # 3 -> rowIndex  (16 choices if K=8 => 2K=16)
      # 4 -> colIndex  (16 choices)
      # 5 -> deltaVal  (3 choices)
      agent_actions:
        - num_choices: 3
        - num_choices: 3
        - num_choices: 3
        - num_choices: 16
        - num_choices: 16
        - num_choices: 3

agent:
  type: MA_POCA
  params:
    learning_rate: 0.0003
    gamma: 0.99
    lambda: 0.95
    hidden_size: 256
    normalize_rewards: false
    value_loss_coeff: 0.9
    baseline_loss_coeff: 0.9
    max_grad_norm: 1.0
    ppo_clip_range: 0.1

    adaptive_entropy: false
    target_entropy: -8.0
    entropy_lambda_lr: 0.0003
    entropy_lambda_initial: 0.0
    entropy_coeff: 0.05

    schedulers:
      lr:
        start_factor: 1.0
        end_factor: 0.0001
        total_iters: 100000

    networks:
      policy_network:
        in_features: 256
        hidden_size: 256

      critic_network:
        value_head:
          in_features: 256
          hidden_size: 256
          dropout_rate: 0.0
        baseline_head:
          in_features: 256
          hidden_size: 256
          dropout_rate: 0.0

      MultiAgentEmbeddingNetwork:
        agent_obs_encoder:
          input_size: 284
          output_size: 256
          dropout_rate: 0.0
          activation: True

        RSA:
          embed_size: 256
          heads: 8
          dropout_rate: 0.0

        agent_embedding_encoder:
          input_size: 256
          output_size: 256
          dropout_rate: 0.0
          activation: True

        obs_actions_encoder:
          state_dim: 256
          action_dim: 6
          output_size: 256
          dropout_rate: 0.0
          activation: True

        agent_id_enc:
          num_freqs: 64
          id_embed_dim: 256

train:
  normalize_states: True
  num_environments: 8
  epochs: 1
  mini_batch_size: 32
  buffer_size: 1024
  batch_size: 1024
  AgentsResetFrequency: 0
  ActionRepeat: 0
  saveFrequency: 20
