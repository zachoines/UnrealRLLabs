environment:
  type: TerraShift
  params:
    PlatformSize: 1.0
    MaxColumnHeight: 1.0
    ObjectSize: [0.10, 0.10, 0.10]
    ObjectMass: 0.2
    GridSize: 50
    MaxSteps: 1024
    NumGoals: 4
    SpawnDelay: 1.0
    RespawnDelay: 1.0
    MaxAgents: 10
    GoalThreshold: 0.2
    AmplitudeRange: [0.0, 10.0]
    WaveOrientationRange: [0.0, 6.28318530718]
    WavenumberRange: [0.0, 1.5]
    PhaseRange: [0.0, 6.28318530718]
    SigmaRange: [0.01, 15.0]
    PhaseVelocityRange: [0.0, 5.0]
    VelocityRange: [-2.0, 2.0]

  shape:
    is_multi_agent: True
    single_agent_obs_size: 37
    max_agents: 10
    action_space:
      type: continuous
      size: 8

agent:
  type: MA_POCA
  params:
    learning_rate: 0.0004
    gamma: 0.99
    lambda: 0.95
    hidden_size: 256
    normalize_rewards: false
    value_loss_coeff: 0.5
    max_grad_norm: 0.5
    ppo_clip_range: 0.1

    adaptive_entropy: false
    target_entropy: -8.0
    entropy_lambda_lr: 0.0003
    entropy_lambda_initial: 0.0
    entropy_coeff: 0.01 # Used when adaptive_entropy is false

    # Policy network parameters
    networks:
      policy_network:
        in_features: 256
        out_features: 8
        hidden_size: 256
        log_std_min: -5.0
        log_std_max: 2.0
      critic_network:
        value_head:
          in_features: 256
          hidden_size: 256
          dropout_rate: 0.0
        baseline_head:
          in_features: 256
          hidden_size: 256
          dropout_rate: 0.0
      MultiAgentEmbeddingNetwork:
        agent_obs_encoder:
          input_size: 37
          output_size: 256
          dropout_rate: 0.0
          activation: True
        RSA:
          embed_size: 256
          heads: 8
          dropout_rate: 0.0
        agent_embedding_encoder:
          input_size: 256
          output_size: 256
          dropout_rate: 0.0
          activation: True
        obs_actions_encoder:
          state_dim: 256
          action_dim: 8
          output_size: 256
          dropout_rate: 0.0
          activation: True

train:
  normalize_states: True
  num_environments: 16
  epochs: 1
  mini_batch_size: 64
  buffer_size: 512
  batch_size: 512
  AgentsResetFrequency: 1024
  ActionRepeat: 3
  saveFrequency: 20
